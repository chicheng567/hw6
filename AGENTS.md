# Repository Guidelines

## Project Structure & Module Organization
Source for the seq2seq QA system lives in `hw6.py`, which wires argument parsing, dataset loading, the Flash-Attention capable transformer, and checkpoint management. Reusable neural building blocks sit in `transformer/` (`Models.py`, `Layers.py`, `SubLayers.py`, etc.), while tokenizer metadata and constants (special tokens, max lengths) live in `transformer/Const.py`. Dataset artifacts stay under `dataset/`: `samsun/` stores ready-to-train SQuAD-style splits and `tifu/` holds Reddit preprocessing outputs generated by `clean_tifu.py` and `split_tifu.py`.

## Build, Test, and Development Commands
Use Python 3.10+ with CUDA-enabled PyTorch. Typical flows:
```bash
python clean_tifu.py --input dataset/tifu/raw.json --output dataset/tifu/tifu_clean.jsonl
python split_tifu.py --input dataset/tifu/tifu_clean.jsonl --output-prefix dataset/tifu/tifu
python hw6.py --mode train --checkpoint_path checkpoints/multitask.pt --batch_size 16 --device cuda:0
python hw6.py --mode eval --checkpoint_path checkpoints/multitask.pt
```
Training requires GPU; point `--device cuda:N` at an available card and shrink length or batch flags during smoke tests to avoid OOMs.

## Coding Style & Naming Conventions
Match the existing Python style: 4-space indentation, type hints (`Dict[str, Any]`) where possible, and descriptive `snake_case` for functions/variables (`run_epoch`, `build_dataloader`). Transformer classes remain `CamelCase` to mirror PyTorch conventions. Prefer dataclasses or small helpers over duplicated logic, and keep modules import-safe so CLI scripts can be tested without side effects.

## Testing Guidelines
There is no dedicated pytest suite, so rely on focused execution checks. For data utilities, run `python clean_tifu.py` and confirm record counts before/after; `split_tifu.py` should emit four JSONL files whose totals equal the source size. For model code, perform a one-epoch dry run (`--epochs 1 --batch_size 4`) on a tiny subset (e.g., `dataset/samsun/debug.json`) and ensure loss decreases and checkpoints serialize. Always re-run `python hw6.py --mode eval ...` against the intended validation split and capture perplexity in your PR.

## Commit & Pull Request Guidelines
Commits follow short, imperative summaries (e.g., “Add flash attention”). Keep related changes together, include rationale in the body if behavior shifts, and avoid noisy formatting-only commits. Pull requests should describe the problem, solution, and validation commands, plus attach the latest eval metrics and checkpoint path. Link issue IDs when available, call out backwards-incompatible interface changes, and note any data regeneration steps (e.g., rerunning `clean_tifu.py`); tables or short text beats screenshots for metric diffs.
